#!/usr/bin/env node
// GENERATED RUNNER: qtests-runner.mjs - auto-created by qtests TestGenerator
// Safe to delete; will be recreated as needed.
// Mirrors bin/qtests-ts-runner behavior (batching, DEBUG_TESTS.md, stable exits).
// Provides batching, summaries, and debug report creation for failing tests.

// qtests Test Runner - Feature-rich CLI with batching, summaries, and debug file
// Restores original functionality while ensuring Jest is launched with project config

import fs from 'fs';
import path from 'path';
import { spawn } from 'child_process';
import os from 'os';
import { createRequire } from 'module';

// ANSI color codes for terminal output
const colors = {
  green: '\u001b[32m',
  red: '\u001b[31m',
  yellow: '\u001b[33m',
  blue: '\u001b[34m',
  magenta: '\u001b[35m',
  cyan: '\u001b[36m',
  white: '\u001b[37m',
  reset: '\u001b[0m',
  bold: '\u001b[1m',
  dim: '\u001b[2m'
};

// Test discovery patterns
const TEST_PATTERNS = [
  /\.test\.(js|ts|jsx|tsx)$/,
  /\.spec\.(js|ts|jsx|tsx)$/,
  /_test\.(js|ts|jsx|tsx)$/,
  /_spec\.(js|ts|jsx|tsx)$/
];

class TestRunner {
  constructor() {
    this.passedTests = 0;
    this.failedTests = 0;
    this.testResults = [];
    this.startTime = Date.now();
    // Mutex to ensure Jest API fallback runs sequentially to avoid conflicts
    this._apiMutex = Promise.resolve();
    // Lazily-initialized reference to Jest's runCLI for in-process fallback
    this._runCLI = null;
  }

  // Parse common truthy env values: '1', 'true', 'yes' (case-insensitive)
  isEnvTruthy(name) {
    const v = process.env[name];
    if (!v) return false;
    const s = String(v).trim().toLowerCase();
    return s === '1' || s === 'true' || s === 'yes';
  }

  // Discover all test files in the project (from current working directory)
  discoverTests(dir = process.cwd(), depth = 0, maxDepth = 10) {
    const testFiles = [];
    if (depth > maxDepth) return testFiles;
    try {
      const entries = fs.readdirSync(dir, { withFileTypes: true });
      for (const entry of entries) {
        const fullPath = path.join(dir, entry.name);
        // Skip node_modules, hidden directories, and demo directory
        if (entry.name.startsWith('.') || entry.name === 'node_modules' || entry.name === 'demo') {
          continue;
        }
        if (entry.isDirectory()) {
          testFiles.push(...this.discoverTests(fullPath, depth + 1, maxDepth));
        } else if (entry.isFile()) {
          const isTestFile = TEST_PATTERNS.some(pattern => pattern.test(entry.name));
          if (!isTestFile) continue;
          // Skip tests in __mocks__ and other ignored folders
          if (fullPath.includes(`${path.sep}__mocks__${path.sep}`)) continue;
          // In generated-tests, only include files that follow the GeneratedTest naming convention
          if (fullPath.includes(`${path.sep}generated-tests${path.sep}`) && !/GeneratedTest/.test(entry.name)) {
            continue;
          }
          testFiles.push(fullPath);
        }
      }
    } catch {
      // Silently skip directories we can't read
    }
    // Optional pattern filter via env to limit scope for large repos/CI
    const pattern = process.env.QTESTS_PATTERN;
    if (pattern) {
      try {
        const rx = new RegExp(pattern);
        return testFiles.filter(f => rx.test(f));
      } catch {
        return testFiles; // invalid pattern, ignore
      }
    }
    return testFiles;
  }

  // Run a single test file via Jest and capture output
  async runTestFile(testFile) {
    const spawnOnce = () => new Promise((resolve) => {
      const startTime = Date.now();
      let stdout = '';
      let stderr = '';

      // Always use Jest with project config and allow empty matches
      const configCandidates = [
        path.join(process.cwd(), 'config', 'jest.config.mjs'),
        path.join(process.cwd(), 'jest.config.mjs')
      ];
      const cfg = configCandidates.find(p => {
        try { return fs.existsSync(p); } catch { return false; }
      });
      const jestArgs = [];
      if (cfg) {
        jestArgs.push('--config', cfg);
      }
      jestArgs.push('--passWithNoTests');
      const fileWorkers = process.env.QTESTS_FILE_WORKERS ? String(process.env.QTESTS_FILE_WORKERS) : '4';
      const inBand = process.env.QTESTS_INBAND === '1' || process.env.QTESTS_INBAND === 'true';
      jestArgs.push(testFile);
      if (inBand) {
        jestArgs.push('--runInBand');
      } else {
        // Default per-file workers for performance without overwhelming sandbox envs
        jestArgs.push(`--maxWorkers=${fileWorkers}`);
      }
      jestArgs.push('--cache', '--no-coverage');

      // Record intended Jest invocation for debugging/tests
      try {
        const sinkPath = path.join(process.cwd(), 'runner-jest-args.json');
        fs.writeFileSync(sinkPath, JSON.stringify(jestArgs), 'utf8');
      } catch {}

      const child = spawn('jest', jestArgs, {
        stdio: ['pipe', 'pipe', 'pipe'],
        shell: true,
        env: {
          ...process.env,
          NODE_ENV: 'test',
          NODE_OPTIONS: [process.env.NODE_OPTIONS || '', '--experimental-vm-modules'].filter(Boolean).join(' ').trim()
        }
      });

      child.stdout.on('data', (data) => { stdout += data.toString(); });
      child.stderr.on('data', (data) => { stderr += data.toString(); });

      child.on('close', (code) => {
        const duration = Date.now() - startTime;
        let output = stdout + stderr;
        if (code !== 0 && !output.trim()) {
          output = 'No output captured from jest. Possible worker crash or environment restriction.';
        }
        resolve({ file: testFile, success: code === 0, duration, output, stdout, stderr });
      });

      child.on('error', (err) => {
        const duration = Date.now() - startTime;
        const msg = (stderr && stderr.trim()) || (err && err.message) || 'Runner error';
        resolve({ file: testFile, success: false, duration, output: msg, stdout, stderr });
      });
    });

    const first = await spawnOnce();
    const crashed = /A jest worker process [^\n]* crashed/i.test(first.output || '');
    const alreadyInBand = process.env.QTESTS_INBAND === '1' || process.env.QTESTS_INBAND === 'true';
    if (!first.success && crashed && !alreadyInBand) {
      console.error(`${colors.yellow}Retrying in-band due to worker crash: ${testFile}${colors.reset}`);
      process.env.QTESTS_INBAND = '1';
      return await this.runTestFile(testFile);
    }
    // If spawn produced no output or appears restricted, fallback to in-process Jest API
    const looksSandboxed = !first.success && (!first.output || /Possible worker crash or environment restriction/i.test(first.output) || /spawn (?:EACCES|EPERM|ENOENT)/i.test(first.output));
    if (looksSandboxed) {
      const start = Date.now();
      const fallback = await this._withAPILock(() => this._runTestFileViaAPI(testFile));
      return { ...fallback, duration: Date.now() - start };
    }
    return first;
  }

  // Ensure only one in-process Jest run executes at a time
  async _withAPILock(fn) {
    const prev = this._apiMutex;
    let resolveNext;
    this._apiMutex = new Promise(res => { resolveNext = res; });
    await prev.catch(() => {});
    try {
      const result = await fn();
      resolveNext();
      return result;
    } catch (err) {
      resolveNext();
      throw err;
    }
  }

  // Fallback: execute Jest via its programmatic API inside this Node process
  async _runTestFileViaAPI(testFile) {
    const startTime = Date.now();
    let stdout = '';
    let stderr = '';
    try {
      if (!this._runCLI) {
        const require = createRequire(import.meta.url);
        const jestModule = require('jest');
        this._runCLI = jestModule && jestModule.runCLI ? jestModule.runCLI : null;
      }
      if (!this._runCLI) {
        const msg = 'Jest API not available for fallback execution.';
        return { file: testFile, success: false, duration: Date.now() - startTime, output: msg, stdout, stderr };
      }
      const configCandidates = [
        path.join(process.cwd(), 'config', 'jest.config.mjs'),
        path.join(process.cwd(), 'jest.config.mjs')
      ];
      const cfg = configCandidates.find(p => { try { return fs.existsSync(p); } catch { return false; } });
      const argv = { runInBand: true, passWithNoTests: true, silent: false, runTestsByPath: true, _: [testFile], $0: 'jest' };
      if (cfg) argv.config = cfg;
      const origLog = console.log, origErr = console.error;
      console.log = (...a) => { try { stdout += a.join(' ') + '\n'; } catch {} origLog.apply(console, a); };
      console.error = (...a) => { try { stderr += a.join(' ') + '\n'; } catch {} origErr.apply(console, a); };
      try {
        const { results } = await this._runCLI(argv, [process.cwd()]);
        const duration = Date.now() - startTime;
        const success = results && results.success === true;
        const mergedOut = (stdout + (stderr ? ('\n' + stderr) : '')).trim();
        return { file: testFile, success, duration, output: mergedOut || (success ? '' : 'Jest API run failed with no output.'), stdout, stderr };
      } finally {
        console.log = origLog;
        console.error = origErr;
      }
    } catch (err) {
      const duration = Date.now() - startTime;
      const msg = (err && (err.stack || err.message)) || 'Jest API fallback error';
      return { file: testFile, success: false, duration, output: msg, stdout, stderr };
    }
  }

  // Print colored status indicator
  printStatus(success, text) {
    const indicator = success ? `${colors.green}${colors.bold}âœ“${colors.reset}` : `${colors.red}${colors.bold}âœ—${colors.reset}`;
    console.log(`${indicator} ${text}`);
  }

  // Print test file result
  printTestResult(result) {
    const { file, success, duration } = result;
    const durationText = `${colors.dim}(${duration}ms)${colors.reset}`;
    const fileText = `${colors.cyan}${file}${colors.reset}`;
    this.printStatus(success, `${fileText} ${durationText}`);
    if (!success && result.output) {
      const lines = result.output.split('\n');
      lines.forEach(line => { if (line.trim()) console.log(`  ${colors.dim}${line}${colors.reset}`); });
    }
  }

  // Generate debug file for failed tests
  generateDebugFile() {
    const failedResults = this.testResults.filter(r => !r.success);
    if (failedResults.length === 0) return;
    if (this.isEnvTruthy('QTESTS_SUPPRESS_DEBUG') || this.isEnvTruthy('QTESTS_NO_DEBUG_FILE')) return;
    const debugFilePath = (process.env.QTESTS_DEBUG_FILE && String(process.env.QTESTS_DEBUG_FILE).trim()) || 'DEBUG_TESTS.md';
    let debugContent = '# Test Failure Analysis\n\n';
    debugContent += 'Analyze and address the following test failures:\n\n';
    failedResults.forEach((result, index) => {
      debugContent += `## Failed Test ${index + 1}: ${result.file}\n\n`;
      debugContent += '### Output:\n';
      debugContent += '```\n';
      debugContent += result.output;
      debugContent += '\n```\n\n';
      debugContent += `### Duration: ${result.duration}ms\n\n`;
      debugContent += '---\n\n';
    });
    debugContent += '## Summary\n\n';
    debugContent += `- Total failed tests: ${failedResults.length}\n`;
    debugContent += `- Failed test files: ${failedResults.map(r => r.file).join(', ')}\n`;
    debugContent += `- Generated: ${new Date().toISOString()}\n`;
    try { fs.writeFileSync(debugFilePath, debugContent); } catch {}
    if (!this.isEnvTruthy('QTESTS_SILENT')) {
      console.log(`\n${colors.yellow}ðŸ“‹ Debug file created: ${debugFilePath}${colors.reset}`);
    }
  }

  // Print comprehensive summary
  printSummary() {
    const duration = Date.now() - this.startTime;
    const totalFiles = this.testResults.length;
    console.log(`\n${colors.bold}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${colors.reset}`);
    console.log(`${colors.bold}${colors.white}           TEST SUMMARY${colors.reset}`);
    console.log(`${colors.bold}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${colors.reset}`);
    const allPassed = this.failedTests === 0;
    const statusColor = allPassed ? colors.green : colors.red;
    const statusText = allPassed ? 'ALL TESTS PASSED' : 'SOME TESTS FAILED';
    console.log(`${statusColor}${colors.bold}${statusText}${colors.reset}\n`);
    console.log(`${colors.green}âœ“ Passed:${colors.reset} ${colors.bold}${this.passedTests}${colors.reset}`);
    console.log(`${colors.red}âœ— Failed:${colors.reset} ${colors.bold}${this.failedTests}${colors.reset}`);
    console.log(`${colors.blue}ðŸ“ Files:${colors.reset} ${colors.bold}${totalFiles}${colors.reset}`);
    console.log(`${colors.magenta}â±  Duration:${colors.reset} ${colors.bold}${duration}ms${colors.reset}`);
    if (this.failedTests > 0) {
      console.log(`\n${colors.red}Failed test files:${colors.reset}`);
      this.testResults.filter(r => !r.success).forEach(r => console.log(`  ${colors.red}â€¢${colors.reset} ${r.file}`));
    }
    console.log(`\n${colors.bold}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${colors.reset}`);
  }

  // Main runner method - optimized for parallel execution
  async run() {
    if (!this.isEnvTruthy('QTESTS_SILENT')) {
      console.log(`${colors.bold}${colors.blue}ðŸ§ª qtests Test Runner - Parallel Mode${colors.reset}`);
      console.log(`${colors.dim}Discovering and running all tests...\n${colors.reset}`);
    }
    const testFiles = this.discoverTests();
    if (testFiles.length === 0) {
      if (!this.isEnvTruthy('QTESTS_SILENT')) {
        console.log(`${colors.yellow}âš   No test files found${colors.reset}`);
        console.log(`${colors.dim}Looked for files matching: ${TEST_PATTERNS.map(p => p.toString()).join(', ')}${colors.reset}`);
      }
      process.exit(0);
    }
    if (!this.isEnvTruthy('QTESTS_SILENT')) {
      console.log(`${colors.blue}Found ${testFiles.length} test file(s):${colors.reset}`);
      testFiles.forEach(file => console.log(`  ${colors.dim}â€¢${colors.reset} ${file}`));
      console.log(`\n${colors.magenta}ðŸš€ Running tests in parallel...${colors.reset}\n`);
    }
    const cpuCount = os.cpus().length;
    const envConcurrency = parseInt(process.env.QTESTS_CONCURRENCY || '', 10);
    const defaultConcurrency = Math.max(4, cpuCount * 2);
    const maxConcurrency = Math.min(
      testFiles.length,
      Number.isFinite(envConcurrency) && envConcurrency > 0 ? envConcurrency : defaultConcurrency
    );
    if (!this.isEnvTruthy('QTESTS_SILENT')) {
      console.log(`${colors.dim}Max concurrency: ${maxConcurrency} workers (${cpuCount} CPU cores)${colors.reset}\n`);
    }

    const runBatch = async (batch) => {
      const results = await Promise.all(batch.map(async (testFile) => {
        const result = await this.runTestFile(testFile);
        if (result.success) this.passedTests++; else this.failedTests++;
        this.printTestResult(result);
        return result;
      }));
      return results;
    };

    for (let i = 0; i < testFiles.length; i += maxConcurrency) {
      const batch = testFiles.slice(i, i + maxConcurrency);
      const batchResults = await runBatch(batch);
      this.testResults.push(...batchResults);
      if (i + maxConcurrency < testFiles.length && !this.isEnvTruthy('QTESTS_SILENT')) {
        console.log(`${colors.dim}Completed batch ${Math.floor(i / maxConcurrency) + 1}, starting next...${colors.reset}\n`);
      }
    }

    if (this.failedTests > 0) this.generateDebugFile();
    this.printSummary();
    process.exit(this.failedTests > 0 ? 1 : 0);
  }
}

// Run the test suite
const runner = new TestRunner();
runner.run().catch(error => {
  console.error(`${colors.red}Test runner error:${colors.reset}`, error);
  process.exit(1);
});

export default TestRunner;

